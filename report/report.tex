\documentclass{llncs}
\usepackage{todonotes}
\usepackage{url}
\usepackage{hyperref}
\usepackage{graphics}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\begin{document}
\title{Exercício Prático 2: MAPC Agents on Mars}

\author{Alan Rafael Fachini\inst{1} \and Lucas Nascimento\inst{1} \and Márcio F. Stabile Jr.\inst{2}}
\institute{PCS-EPUSP \and IME-USP}

\maketitle

\begin{abstract}
Este relatório descreve a implementação de um time usando a abordagem de sistema multi-agente para o cenário \textit{Agents on Mars} desenvolvida pelo ``Multi-Agent Programming Contest'' (MAPC) \footnote{MAPC page: \url{http://multiagentcontest.org/2013}}. Neste cenário os agentes devem encontrar as melhores zonas com os maiores pesos nos nós do grafo. A implementação apresentada usou como base o sistema do time LTI-USP desenvolvida por Franco e Sichman \cite{franco2013improving} para a competição de 2013, e testes com estratégias diferentes para a organização dos times foram realizados a fim de tentar identificar estratégias mais eficientes.
\end{abstract}

\section{Introdução}

O MAPC é uma competição realizada todos os anos, onde são propostos problemas de domínios variados para a resolução utilizando sistemas Multi-agentes. Seu principal objetivo é o fomento a pesquisa nessa área de estudo. No MAPC, dois times de agentes competem no mesmo ambiente, oferecendo assim uma oportunidade para a comparação de estratégias e arquiteturas. Desde 2011 o cenário proposto, \textit{Agents on Mars}, incentiva soluções baseadas em cooperação e coordenação. O objetivo geral do cenário é o controle de zonas em um mapa, representado por um grafo, por se posicionar os agentes em posições, vértices apropriados. A história de fundo do cenário gira em torno da exploração de marte por áreas com concentração de água.

O presente artigo apresenta a estratégia para o time ALM, desenvolvido com base no modelo do time LTI-USP \cite{franco2013comparing}\cite{franco2013improving}\cite{ltiusp2012}. O time ALM foi desenvolvido como parte da avaliação da disciplina de Sistemas Multi-Agentes pelos alunos Alan Fachini, Lucas Nascimento dos Santos da Silva e Márcio Fernando Stabile Júnior. Os experimentos realizados bem como dados estatísticos gerados podem ser acessados no repositório de código deste projeto \footnote{Repositório de Código: \url{https://github.com/mfstabile/PCS5703}}.

\section{Projeto do Sistema}

O time ALM foi desenvolvido com base no time LTI-USP participante das competições de 2012 e 2013. O time ALM, assim como o time em que é baseado, utiliza o arcabouço de desenvolvimento para sistemas multi-agentes JaCaMo \cite{jacamo-scp78}. JaCaMo é uma plataforma para a programação de sistemas multi-agentes que suporta vários níveis de abstração (agentes, ambiente, organização). Para tal, o JaCaMo combina três tecnologias: Jason \cite{bordini2007jason}, para programar agentes autônomos; CArtAgO (Common ARTifact infrastructure for AGents Open environments) \cite{ricci2011cartago}, para programar artefatos do ambiente e Moise \cite{hubner2010moise}, para programar organizações de multi-agentes.

Adotou-se como metodologia de desenvolvimento para este projeto uma prática iterativa, onde testes foram sendo realizados até se conseguir o melhor resultado nas simulações.

Baseado no time LTI-USP da versão da competição de 2013, nosso time apresenta uma proposta não centralizada. Apesar de apresentar um agente coordenador, cada agente possui autonomia para decidir quais vértices irá ocupar para criar ou expandir uma zona. Cada agente possui seu modelo interno do ambiente e se comunica com outros agentes para informar a estrutura do mapa, posições dos oponentes ou solicitar reparos. De acordo com as regras da competição de 2013 o time é composto de 28 agentes\cite{franco2013improving}.

A arquitetura dos agentes é baseada no modelo BDI, com cada agente possuindo sua base de crenças, desejos e intenções. Cada agente tem autonomia para decidir sua próxima ação em cooperação com os demais.

Os agentes se comunicam em forma de \textit{broadcast} enviando, uns para os outros, mensagens somente em relação às suas novas percepções, assim os agentes só enviam mensagens nos casos em que a percepção altera o modelo interno do ambiente do agente. A sobrecarga causada por esse tipo de comunicação no começo da simulação, quando as percepções recebidas pelos agentes são novas, diminui com o progresso da simulação conforme os agentes completam um modelo do ambiente.

O ALM é um sistema multi-agente real no sentido que seus agentes são autônomos, proativos e reativos. São autônomos no sentido de decidir por si próprios qual a próxima ação a ser realizada, ainda que em coordenação com outros agentes e com o agente coordenador. Eles apresentam comportamento proativo quando selecionam o melhor vértice no mapa para se movimentarem. E apresentam comportamento reativo quando, por exemplo, o agente realiza uma recarga ao ficar com baixa energia.

\section{Arquitetura}

A arquitetura do time ALM, exibida na Figura \ref{fig:arquitetura}, baseia-se na arquitetura do time LTI-USP. Nessa arquitetura a linguagem de programação Jason foi utilizada para a programação dos agentes. Ela provê uma abstração do modelo BDI, disponibilizando conceitos tais como planos, crenças e objetivos. Jason é baseado na plataforma Java e implementa uma extensão da linguagem de programação para agentes AgentSpeak. Jason provê atos de fala que são utilizados no trabalho para a comunicação dos agentes. Uma vantagem da utilização da linguagem Jason é a possibilidade de invocar métodos escritos em Java o que permite maior versatilidade na implementação dos agentes e suas ações \cite{bordini2007jason}. No time LTI-USP a representação interna dos agentes do mundo, ou ambiente, foi implementada na forma de um grafo e o agente decide qual plano utilizar de acordo com suas crenças e representação interna do mundo. O modelo interno do mundo utilizado pelos agentes foi criado em Java usando estruturas de dados e classes, que representam todos os aspectos recebidos do simulador. A cada interação da simulação os agentes atualizam seu modelo interno do mundo de acordo com as percepções recebidas do servidor \cite{ltiusp2012}.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\linewidth]{./images/arquitetura.png}
\caption{Arquitetura dos times LTI-USP e ALM.}
\label{fig:arquitetura}
\end{figure}

O arcabouço CArtAgO foi utilizado para acessar os artefatos organizacionais disponíveis em Moise. CArtAgO é um arcabouço para programação de ambientes baseada em Agentes \& Artifacts (A\&A) para desenhar e modelar sistemas multi-agentes. Ele inclui várias metáforas baseadas em ambientes cooperativos de sociedades humanas, tais como: agentes como entidades computacionais que executam uma tarefa (análogo a trabalhadores humanos); artefatos como recursos; e ferramentas dinamicamente construídas para o uso e manipulação dos agentes na execução de suas tarefas. Cada artefato pode ser usado e manipulado pelos agentes em tempo de execução \cite{ricci2011cartago}. Nesse trabalho não foram desenhados novos artefatos para o uso dos agentes, tal qual o trabalho no qual o presente projeto é baseado os únicos artefatos existentes são os relacionados ao modelo organizacional feito em Moise.

Moise é um modelo organizacional para sistemas multi-agentes baseado em três dimensões: estrutural, funcional e normativa. A dimensão estrutural é construída sob três níveis. O nível individual responde pelo comportamento que um agente adota ao assumir determinado papel. O nível social diz respeito à relação entre papeis e comunicação. E o nível coletivo responde pela agregação de papéis em grupos. A dimensão funcional é formada por planos, metas e missões que representam a forma pela qual o sistema multi-agentes alcança o seu objetivo global. O objetivo global é decomposto em planos, que são distribuídos aos agentes na forma de missões, quando um agente recebe uma missão ele se responsabiliza por todas as metas que compõem a missão. E a dimensão normativa, ou deôntica, abrange a autonomia dos agentes, especificando o que é ou não permitido dentro da organização. A especificação dessa dimensão diz respeito às permissões e obrigações relacionadas a um papel. O modelo em Moise permite ao desenvolvedor delimitar as restrições da sociedade de agentes, e também pode ser usada para que os agentes raciocinem em relação a sua organização \cite{hubner2010moise}.

Os agentes se comunicam com o servidor MASSim por meio da interface EISMASSim, baseada em EIS, e distribuída pela organização da competição. Para realizar a comunicação com a interface do servidor com a competição a arquitetura padrão foi alterada pelo time LTI-USP para atuar não somente em artefatos do CArtAgO, como também no ambiente EIS.

\section{Estratégias}\label{sec:strategies}

O cenário do MAPC define cinco tipos diferentes de agentes, cada um com sua especialidade: explorador, reparador, sabotador, sentinela e inspetor. Cada classe de agente tem um conjunto de ações que lhe são permitidas, a Tabela \ref{table:tab1} exibe qual o conjunto de ações permitidas para cada tipo de agente.

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
	\hline
	         & explorador & reparador & sabotador & sentinela & inspetor \\ \hline
	\textit{recharge} &      X      &     X      &     X      &    X       & X \\ \hline
  \textit{attack}  &            &           &     X      &           &  \\ \hline
  \textit{parry}   &            &     X      &    X       &    X       &  \\ \hline
  \textit{goto}   &     X       &     X      &   X        &    X       & X  \\ \hline
  \textit{probe}   &     X       &           &           &           &  \\ \hline
  \textit{survey}  &      X      &     X      &    X       &    X       & X \\ \hline
  \textit{inspect}  &            &           &           &           &  X\\ \hline
  \textit{buy}    &     X       &     X      &     X      &   X        & X \\ \hline
  \textit{repair}  &            &      X     &           &           &  \\ \hline
  \textit{skip}   &    X        &     X      &    X       &   X        & X \\ \hline
\end{tabular}
\caption{Conjunto de ações por agente definido pelo MAPC.}
\label{table:tab1}
\end{table}

Usando como base o time LTI-USP, os papeis assumidos por nossos agentes não são diretamente mapeáveis para os times definidos para a competição. Assim tipos adicionais de agentes foram definidos de acordo com a estratégia usada. Cada papel tem uma missão associada que pode ser assumida por um ou mais tipos de agente. O time LTI-USP define alguns tipos diferentes de agentes: \textit{map\_explorer} (explorador), \textit{map\_explorer\_helper} (explorador), \textit{soldier} (todos os tipos), \textit{guardian} (sabotador), \textit{medic} (reparador), \textit{zone\_explorer} (explorador), \textit{saboteur} (sabotador), \textit{sentinel} (sentinela), \textit{repairer} (reparador), \textit{coordinator} (nenhum). Uma descrição detalhada de cada tipo pode encontra-se em \cite{franco2013improving}.

Em relação ao modelo de agentes utilizado pelo time LTI-USP, o time ALM muda um pouco a estrutura e os tipos utilizados. Nossa abordagem não utiliza os agentes do tipo \textit{guardian}, optando por uma estratégia mais agressiva de ataque possuindo mais agentes do tipo \textit{saboteur} com a missão exclusiva de eliminar oponentes. Seguindo essa linha, devido ao maior número de agentes do tipo \textit{saboteur} atacando preferimos transferir um agente do tipo \textit{soldier} responsável por manter as zonas ocupadas, para o tipo \textit{repairer} no grupo de ataque, para prestar assistência aos agentes \textit{saboteur}. A Figura \ref{fig:fig2} mostra como ficou o modelo Moise após essas alterações.

Para garantir o comportamento desejado dos agentes, além do modelo organizacional, foi necessário alterar também as missões as quais cada um dos agentes se compromete. Na estratégia desenvolvida os quatro agentes \textit{saboteur} se comprometem com a missão de atacar todos os agentes inimigos enquanto os agentes \textit{repairer} receberam a missão de reparar os \textit{saboteur} conforme sua ajuda fosse solicitada. Com a remoção dos agentes \textit{guardian}, a missão de defender as zonas dominadas deixou de ser utilizada.

Por fim, a estratégia do time pode ser resumida da seguinte forma: Existem três principais grupos. O primeiro, de ataque, é responsável por procurar e sabotar os agentes do outro time. Os outros dois grupos sao responsáveis por localizar e ocupar as duas melhores zonas do mapa encontradas. Cada um desses grupos contém \textit{soldiers} que são responsáveis por delimitar a área, um \textit{medic} que se posiciona no meio da zona dominada e tem a missão de reparar os agentes danificados e um \textit{zone\_explorer} que examina os nós da área ocupada.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\linewidth]{./images/fig2.png}
\caption{Modelo Moise dos tipos de agente utilizados pelo time ALM}
\label{fig:fig2}
\end{figure}

\section{Experimentos}

As partidas no ambiente MAPC acontecem em mapas gerados aleatoriamente dados parâmetros que definem o número de arestas e vértices. Cada time joga três vezes um contra o outro em partidas que duram 750 passos. Para os experimentos realizados neste trabalho escolheu-se reduzir o número de passos para 200, visto que nos experimentos realizados um dos times já havia vencido até esse passo.

Os experimentos realizados colocaram o time ALM para competir contra o time LTI-USP que ficou em terceiro lugar na competição MAPC de 2013. Os times competiram em quatro ambientes diferentes definidos pelas propriedades apresentadas na Tabela \ref{table:ambientes}. Foram testados também ambientes com diferentes quantidades de vértices e arestas. A coluna semente define a semente utilizada para se gerar os mapas. Também é possível encontrar os arquivos de configuração utilizados no repositório de código deste trabalho \footnote{Repositório de Código: \url{https://github.com/mfstabile/PCS5703}}. A Figura \ref{fig:ambientes-testes} apresenta a representação gráfica dos ambientes utilizados nos testes.

\begin{table}[!h]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
  \hline
               & ~Vértices~ & ~Arestas~ &    Semente    \\ \hline
  ~Ambiente 1~ &   500    &   40\%  & ~1402107246426~ \\ \hline
  ~Ambiente 2~ &   500    &   40\%  & ~1402129496795~ \\ \hline
  ~Ambiente 3~ &   600    &   10\%  & ~1402141987750~ \\ \hline
  ~Ambiente 4~ &   400    &   20\%  & ~1402235674563~ \\ \hline
\end{tabular}
\caption{Conjunto de ações por agente.}
\label{table:ambientes}
\end{table}

\begin{figure}[!ht]
      \centering
      \begin{subfigure}[b]{0.48\textwidth}
              \includegraphics[width=\textwidth]{images/sim1.png}
              \caption{Ambiente 1}
              \label{fig:ambiente1}
      \end{subfigure}
      ~
      \begin{subfigure}[b]{0.48\textwidth}
              \includegraphics[width=\textwidth]{images/sim2.png}
              \caption{Ambiente 2}
              \label{fig:ambiente2}
      \end{subfigure}
      ~
      \begin{subfigure}[b]{0.48\textwidth}
              \includegraphics[width=\textwidth]{images/sim3.png}
              \caption{Ambiente 3}
              \label{fig:ambiente3}
      \end{subfigure}
      ~
      \begin{subfigure}[b]{0.48\textwidth}
              \includegraphics[width=\textwidth]{images/sim4.png}
              \caption{Ambiente 4}
              \label{fig:ambiente4}
      \end{subfigure}
      \caption{Ambientes testados nos experimentos}
      \label{fig:ambientes-testes}
\end{figure}

\section{Análise dos Resultados}

\begin{figure}[!ht]
\centering
\includegraphics[width=1\linewidth]{./images/simulations-chart.png}
\caption{Resultado das simulações realizadas}
\label{fig:resultados}
\end{figure}

Para cada ambiente apresentado foram realizados 12 simulações de jogos entre os times ALM e LTI-USP. A Figura \ref{fig:resultados} apresenta a pontuação final dos times nos jogos para os quatro ambientes.

Como se pode notar, a alteração realizada no time ALM fez com que o time obtivesse a maioria das vitórias nas simulações geradas. O time ALM não possui agentes guardiões para defender as áreas conquistadas. Estes agentes foram alterados para procurar e atacar os agentes do time adversário, ficando o time com 4 agentes sabotadores com o objetivo de atacar. O time também possui dois agentes para reparar os sabotadores. Esta alteração foi realizada no time para forçar os agentes a atacarem o time adversário. Podemos perceber durante a execução das simulações que em muitas vezes o time adversário começava com uma pontuação maior, porém após o time ALM realizar seus ataques o time adversário se tornou ineficiente, perdendo a partida.

A maioria das derrotas do time ALM aconteceram no Ambiente 2. Inferimos que o fato desse ambiente possuir zonas dispersas colaborou para a menor pontuação. O time LTI-USP está preparado para encontrar, dominar e defender duas zonas no mapa, e mapas com zonas dispersas podem favorecer este time. Porém mesmo neste mapa, para 12 simulações geradas, o time ALM sofreu apenas 4 derrotas. Pode-se notar que nas partidas 2 e 10 o time LTI-USP poderia ter derrotado o time ALM. Este ambiente também é o com menor pontuação pois as zonas são pequenas, dificultando que os agentes consigam atingir pontuações maiores.

Podemos perceber também que o Ambiente 4, com duas grandes zonas separadas, gerou a segunda menor pontuação média entre os 4 ambientes. Baseados nas simulações do Ambiente 2 e 4 acreditamos que o time ALM tenha mais dificuldade em lidar com ambientes com zonas dispersas, quanto maior a quantidade de zonas, pior o desempenho do time.

Os Ambientes 1 e 3 mostram que em ambientes com uma grande zona o time ALM se destaca do time adversário com uma pontuação muito maior. Como os times disputam a mesma zona, o time ALM acaba atacando o adversário que perde desempenho durante a partida.

\begin{table}
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
               & p-value \\ \hline
    ~Ambiente 1~ & ~~0.00221772146424~ \\ \hline
    ~Ambiente 2~ & \textit{0.0230957326175} \\ \hline
    ~Ambiente 3~ & ~~0.00221772146424~ \\ \hline
    ~Ambiente 4~ & ~~0.00474176803841~ \\ \hline
  \end{tabular}
  \caption{Wilcoxon T-test para as simulações realizadadas nos quatro ambientes.}
  \label{table:wilcoxon}
\end{table}

A Tabela \ref{table:wilcoxon} apresenta o \textit{p-value} para o teste de Wilcoxon \footnote{\url{http://vassarstats.net/textbook/ch12a.html}} que nos ajuda a definir se a quantidade de simulações geradas são suficientes para determinar se um time é melhor que outro em determinado Ambiente. Um valor abaixo de 0.05 para o \textit{p-value} indica que os resultados obtidos nas 12 simulações são suficientes para caracterizar que um time tem tendência a obter pontuações maiores que o outro. Podemos notar que o \textit{p-value} para o Ambiente 2 nos indica que os resultados obtidos não são suficientes para se tirar uma conclusão definitiva sobre qual time tem uma tendência de vencer neste ambiente, corroborando nossa hipótese de que neste ambiente o time ALM desempenha pior do que nos outros.

\section{Conclusão}

Neste trabalho realizamos modificações na estrutura organizacional e nas missões dos agentes do sistema LTI-USP para criar o time ALM. Para nosso time, adotamos a estratégia de colocar agentes para atacar e reparar e não utilizamos nenhum agente para defender as zonas conquistadas. Nos testes realizamos para 4 ambientes diferentes podemos verificar que esta estratégia faz com que o time ALM vença a maioria das partidas contra o time LTI-USP.

Determinar a melhor organização de um sistema multi-agente é um problema difícil. Foi necessário testar de forma empírica diversas estratégias e modificações incrementais no sistema para chegar em uma estratégia que fosse vitoriosa. O tempo de execução dos testes também gerou um desafio para resolver o problema. Acreditamos que os resultados aqui apresentados não são conclusivos. Testes contra os demais times vitoriosos da competição são necessários para verificar se a estratégia aqui adotada é suficiente para que os agentes ajam de forma eficiente para vencer as partidas. Também é necessário realizar mais testes realizando modificações no comportamento dos agentes. Acreditamos que usando agentes que possam modificar suas missões durante a partida pode gerar times mais fortes.

Como trabalho futuro propomos a realização de mais testes contra outros times e em outros ambientes. Também é interessante investigar o uso de agentes capazes de modificar suas missões, ou um sistema onde o coordenador modifique as missões dos outros agentes para melhorar o desempenho dos agentes de acordo com modificações no ambiente.

Por fim, este trabalho foi importante por mostrar como a área de Sistemas Multi-Agentes pode prover abordagens diferentes para problemas de Engenharia de \textit{Software}. O uso do conceito de organização e agentes tentando realizar missões pode ser utilizado em aplicações de \textit{software} que façam uso de inteligência para resolver problemas reais.

\bibliography{references}{}
\bibliographystyle{plain}

\end{document}

